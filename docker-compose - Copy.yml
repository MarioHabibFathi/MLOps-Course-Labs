version: "3.8"

services:
  app:
    build: .
    container_name: ml-api
    ports:
      - "8000:8000"
    depends_on:
      mlflow:
        condition: service_healthy
      prometheus:
        condition: service_started
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    networks:
      - monitor-net

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - monitor-net

  grafana:
    image: grafana/grafana
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana-storage:/var/lib/grafana
    networks:
      - monitor-net

  mlflow:
    build:
      context: .
      dockerfile: Dockerfile-mlflow
    container_name: mlflow
    volumes:
      - /c/Users/mario/mlruns:/mlflow
    working_dir: /mlflow
    environment:
      - MLFLOW_TRACKING_URI=sqlite:///mlflow/mlflow.db
    #command: mlflow server --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root /mlflow
    command: >
      bash -c "pip install mlflow && 
      mlflow server
      --backend-store-uri sqlite:////mlruns/mlflow.db
      --default-artifact-root file:///mlruns
      --host 0.0.0.0
      --port 5000"
    ports:
      - "5000:5000"
    networks:
      - monitor-net     
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 40s


volumes:
  grafana-storage:
networks:
  monitor-net:
